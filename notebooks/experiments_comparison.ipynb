{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6cdaf0aea1464e",
   "metadata": {},
   "source": [
    "## Model Comparison & Method Selection\n",
    "\n",
    "## Purpose\n",
    "This notebook documents our experimental process for selecting optimal preprocessing methods and classification. Results from this notebook will inform final implementation decisions in the main analysis notebook.\n",
    "\n",
    "**Note**: This is an experimental notebook. Only winning approaches will be implemented in the production notebook [sentiment_analysis](/notebooks/sentiment_analysis.ipynb).\n",
    "\n",
    "1. Examine Dataset for Normalization Decisions\n",
    "2. spaCy vs NLTK Lemmatization Comparison\n",
    "3. Spelling Correction Impact Analysis"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T12:42:37.006770Z",
     "start_time": "2025-12-08T12:42:36.805216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Download spaCy model (silent)\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    print(\"spaCy model loaded successfully!\")\n",
    "except OSError:\n",
    "    print(\"Downloading spaCy model...\")\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"],\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.DEVNULL\n",
    "    )\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    print(\"spaCy model downloaded successfully!\")\n",
    "\n",
    "# Download NLTK resources (silent)\n",
    "nltk_resources = ['punkt', 'punkt_tab', 'stopwords', 'wordnet', 'omw-1.4']\n",
    "for resource in nltk_resources:\n",
    "    nltk.download(resource, quiet=True)\n",
    "print(\"NLTK resources ready!\")\n"
   ],
   "id": "27a8cdadccd749bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model loaded successfully!\n",
      "NLTK resources ready!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T12:42:37.044232Z",
     "start_time": "2025-12-08T12:42:37.023010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('../data/customer_sentiment.csv')"
   ],
   "id": "873dc5be348047a3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "8166e55a51d1633c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T12:42:37.189144Z",
     "start_time": "2025-12-08T12:42:37.049132Z"
    }
   },
   "source": [
    "# Exam the dataset for normalization decision\n",
    "print(\"\\n1. SAMPLE REVIEW TEXTS (first 10):\")\n",
    "for i, review in enumerate(data['review_text'].head(10), 1):\n",
    "    print(f\"\\n   {i}. {review[:100]}\")\n",
    "\n",
    "# Platform distribution\n",
    "print(\"\\n2. PLATFORM DISTRIBUTION:\")\n",
    "print(data['platform'].value_counts())\n",
    "\n",
    "# Get all words from reviews (lowercased)\n",
    "all_words = ' '.join(data['review_text'].str.lower()).split()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "print(\"\\n3. TOP 50 MOST COMMON WORDS IN REVIEWS:\")\n",
    "for word, count in word_counts.most_common(50):\n",
    "    print(f\"   {word.ljust(20)} {count}\")\n",
    "\n",
    "# Check for retail/delivery terms\n",
    "retail_terms = ['delivery', 'deliver', 'delivered', 'shipping', 'shipped', 'ship',\n",
    "                'refund', 'return', 'returned', 'money', 'back',\n",
    "                'order', 'ordered', 'ordering', 'package', 'packaging',\n",
    "                'quality', 'product', 'service', 'customer']\n",
    "\n",
    "print(\"\\n4. FREQUENCY OF RETAIL/DELIVERY TERMS:\")\n",
    "for term in retail_terms:\n",
    "    count = sum(1 for review in data['review_text'].str.lower() if term in review)\n",
    "    if count > 0:\n",
    "        print(f\"   {term.ljust(15)} appears in {count} reviews ({count / len(data) * 100:.1f}%)\")\n",
    "\n",
    "# Check platform mentions in text\n",
    "print(\"\\n5. PLATFORM NAMES MENTIONED IN REVIEWS:\")\n",
    "platforms = data['platform'].unique()\n",
    "platform_mentions = 0\n",
    "for platform in platforms:\n",
    "    count = sum(1 for review in data['review_text'].str.lower() if platform.lower() in review)\n",
    "    if count > 0:\n",
    "        print(f\"   {platform.ljust(20)}: mentioned {count} times\")\n",
    "        platform_mentions += 1\n",
    "if platform_mentions == 0:\n",
    "    print(\"   No platform names mentioned in reviews\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. SAMPLE REVIEW TEXTS (first 10):\n",
      "\n",
      "   1. very disappointed with the quality.\n",
      "\n",
      "   2. fast delivery and great packaging.\n",
      "\n",
      "   3. very disappointed with the quality.\n",
      "\n",
      "   4. product stopped working after few days.\n",
      "\n",
      "   5. neutral about the quality.\n",
      "\n",
      "   6. amazing experience, highly recommend!\n",
      "\n",
      "   7. great value for money.\n",
      "\n",
      "   8. excellent product! exceeded expectations.\n",
      "\n",
      "   9. product is okay, nothing special.\n",
      "\n",
      "   10. great value for money.\n",
      "\n",
      "2. PLATFORM DISTRIBUTION:\n",
      "platform\n",
      "nykaa                   1301\n",
      "snapdeal                1289\n",
      "others                  1286\n",
      "reliance digital        1279\n",
      "zepto                   1278\n",
      "facebook marketplace    1272\n",
      "paytm mall              1271\n",
      "myntra                  1267\n",
      "croma                   1266\n",
      "flipkart                1264\n",
      "boat                    1257\n",
      "lenskart                1241\n",
      "jiomart                 1240\n",
      "meesho                  1240\n",
      "ajio                    1234\n",
      "bigbasket               1230\n",
      "shopclues               1220\n",
      "tata cliq               1201\n",
      "swiggy instamart        1192\n",
      "amazon                  1172\n",
      "Name: count, dtype: int64\n",
      "\n",
      "3. TOP 50 MOST COMMON WORDS IN REVIEWS:\n",
      "   the                  6978\n",
      "   delivery             5023\n",
      "   quality.             4952\n",
      "   and                  3992\n",
      "   packaging.           3992\n",
      "   product              3972\n",
      "   very                 3932\n",
      "   with                 3932\n",
      "   great                3919\n",
      "   was                  3038\n",
      "   amazing              2109\n",
      "   experience,          2109\n",
      "   highly               2109\n",
      "   recommend!           2109\n",
      "   is                   2064\n",
      "   late                 2044\n",
      "   poor                 2044\n",
      "   not                  2026\n",
      "   worth                2026\n",
      "   price.               2026\n",
      "   customer             2007\n",
      "   service              2007\n",
      "   unhelpful.           2007\n",
      "   satisfied            1980\n",
      "   value                1971\n",
      "   for                  1971\n",
      "   money.               1971\n",
      "   excellent            1970\n",
      "   product!             1970\n",
      "   exceeded             1970\n",
      "   expectations.        1970\n",
      "   disappointed         1952\n",
      "   fast                 1948\n",
      "   stopped              1908\n",
      "   working              1908\n",
      "   after                1908\n",
      "   few                  1908\n",
      "   days.                1908\n",
      "   okay,                1033\n",
      "   nothing              1033\n",
      "   special.             1033\n",
      "   fine,                1031\n",
      "   decent.              1031\n",
      "   neutral              1020\n",
      "   about                1020\n",
      "   works                1018\n",
      "   fine                 1018\n",
      "   but                  1018\n",
      "   could                1018\n",
      "   be                   1018\n",
      "\n",
      "4. FREQUENCY OF RETAIL/DELIVERY TERMS:\n",
      "   delivery        appears in 5023 reviews (20.1%)\n",
      "   deliver         appears in 5023 reviews (20.1%)\n",
      "   money           appears in 1971 reviews (7.9%)\n",
      "   packaging       appears in 3992 reviews (16.0%)\n",
      "   quality         appears in 4952 reviews (19.8%)\n",
      "   product         appears in 5942 reviews (23.8%)\n",
      "   service         appears in 2007 reviews (8.0%)\n",
      "   customer        appears in 2007 reviews (8.0%)\n",
      "\n",
      "5. PLATFORM NAMES MENTIONED IN REVIEWS:\n",
      "   No platform names mentioned in reviews\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Decision Notes:\n",
    "\n",
    "* No platforms mentioned in text - platform normalization unnecessary\n",
    "* Terms are already simple - \"delivery\", \"quality\", \"product\" are base forms\n",
    "* Lemmatization could be considered for words like \"delivered\" -> \"deliver\",\n",
    "* \"ordered\" -> \"order\",\"packaging\" -> \"package\"\n",
    "* Reviews are short - complex normalization adds small value\n",
    "* Decision: (clean + lemmatize + stopwords)*"
   ],
   "id": "6e3748524ae25142"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## spaCy vs NLTK Lemmatization Comparison",
   "id": "1f18240d17d5d00d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T12:44:41.895725Z",
     "start_time": "2025-12-08T12:43:37.308305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize tools\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Text Cleaning Function\n",
    "def clean_text(text):\n",
    "    \"\"\" Clean and Normalize Text Data\n",
    "     Steps:\n",
    "      1. Lowercase the text\n",
    "      2. Remove URLs\n",
    "      3. Remove emails addresses\n",
    "      4. Remove punctuation\n",
    "      5. Remove extra whitespace\n",
    "     \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Tokenization Function\n",
    "def tokenize_text(text):\n",
    "    \"\"\" Tokenize text into words \"\"\"\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Stopword Removal Function\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"\n",
    "     Remove common English stopwords, but keep negations.\n",
    "     Like: not, no, n't, don't, doesn't, didn't, never, none, nobody, nothing, neither, nor\n",
    "     Negations are crucial for sentiment analysis.\n",
    "     \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    negations = {\"not\", \"no\", \"n't\", \"don't\", \"doesn't\", \"didn't\",\n",
    "                 \"never\", \"none\", \"nobody\", \"nothing\", \"neither\", \"nor\"}\n",
    "    return [words for words in tokens if words not in stop_words or words in negations]\n",
    "\n",
    "# Lemmatization Functions\n",
    "def lemmatize_tokens_nltk(tokens):\n",
    "    \"\"\" Lemmatize text using NLTK's WordNetLemmatizer\n",
    "    Example:\n",
    "        packages -> package\n",
    "        delivered -> deliver\n",
    "    \"\"\"\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "def lemmatize_tokens_spacy(tokens):\n",
    "    \"\"\" Lemmatize text using spaCy\n",
    "    Example:\n",
    "      running -> run, better -> good | While NLTK may not handle these well\n",
    "    \"\"\"\n",
    "    text = ' '.join(tokens)\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "# Preprocessing Pipeline\n",
    "def preprocess_pipeline(text, method='nltk'):\n",
    "    \"\"\" Complete Preprocessing Pipeline\n",
    "     method: 'nltk' or 'spacy' for lemmatization\n",
    "    \"\"\"\n",
    "    text = clean_text(text)\n",
    "    tokens = tokenize_text(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "\n",
    "    if method == 'nltk':\n",
    "        tokens = lemmatize_tokens_nltk(tokens)\n",
    "    elif method == 'spacy':\n",
    "        tokens = lemmatize_tokens_spacy(tokens)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'nltk' or 'spacy'\")\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Sample Comparison\n",
    "print(\"\\nPreprocessing Comparison: NLTK vs spaCy (Sample)\")\n",
    "sample_size = 5\n",
    "for i in range(sample_size):\n",
    "    original = df.loc[i, 'review_text']\n",
    "    nltk_result = preprocess_pipeline(original)\n",
    "    spacy_result = preprocess_pipeline(original, method='spacy')\n",
    "\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"NLTK:     {nltk_result}\")\n",
    "    print(f\"spaCy:    {spacy_result}\")\n",
    "\n",
    "# Execution Time Test\n",
    "print(f\"\\nExecution Time Comparison - Processing {len(df):,} reviews\")\n",
    "\n",
    "# NLTK timing\n",
    "print(\"Testing NLTK...\")\n",
    "start_time = time.time()\n",
    "df['processed_text_nltk'] = df['review_text'].apply(preprocess_pipeline)\n",
    "nltk_time = time.time() - start_time\n",
    "print(f\"NLTK Lemmatization: {nltk_time:.2f} seconds\")\n",
    "\n",
    "# spaCy timing\n",
    "print(\"Testing spaCy...\")\n",
    "start_time = time.time()\n",
    "df['processed_text_spacy'] = df['review_text'].apply(lambda x: preprocess_pipeline(x, method='spacy'))\n",
    "spacy_time = time.time() - start_time\n",
    "print(f\"spaCy Lemmatization: {spacy_time:.2f} seconds\")\n",
    "\n",
    "# Speed comparison\n",
    "print(f\"\\nSpeed Comparison:\")\n",
    "print(f\"spaCy is {spacy_time/nltk_time:.2f}x slower than NLTK\")\n",
    "print(f\"Time difference: {spacy_time - nltk_time:.2f} seconds\")"
   ],
   "id": "9cd9b52064544827",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Comparison: NLTK vs spaCy (Sample)\n",
      "\n",
      "Sample 1:\n",
      "Original: very disappointed with the quality.\n",
      "NLTK:     disappointed quality\n",
      "spaCy:    disappoint quality\n",
      "\n",
      "Sample 2:\n",
      "Original: fast delivery and great packaging.\n",
      "NLTK:     fast delivery great packaging\n",
      "spaCy:    fast delivery great packaging\n",
      "\n",
      "Sample 3:\n",
      "Original: very disappointed with the quality.\n",
      "NLTK:     disappointed quality\n",
      "spaCy:    disappoint quality\n",
      "\n",
      "Sample 4:\n",
      "Original: product stopped working after few days.\n",
      "NLTK:     product stopped working day\n",
      "spaCy:    product stop work day\n",
      "\n",
      "Sample 5:\n",
      "Original: neutral about the quality.\n",
      "NLTK:     neutral quality\n",
      "spaCy:    neutral quality\n",
      "\n",
      "Execution Time Comparison - Processing 25,000 reviews\n",
      "Testing NLTK...\n",
      "NLTK Lemmatization: 2.52 seconds\n",
      "Testing spaCy...\n",
      "spaCy Lemmatization: 62.05 seconds\n",
      "\n",
      "Speed Comparison:\n",
      "spaCy is 24.66x slower than NLTK\n",
      "Time difference: 59.53 seconds\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ">We observe that while spaCy provides better verb normalization, smaller vocabularies. However, it is more aggressive, and it is **~ 23.83x slower** than NLTK. Given our large dataset size **(25,000 reviews)** and the relatively minor differences in lemmatization for our specific use case, we will proceed with NLTK for lemmatization in our final preprocessing pipeline.",
   "id": "1f0ad92b78b554b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T12:45:08.383829Z",
     "start_time": "2025-12-08T12:44:41.912285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to check if word is misspelled\n",
    "def is_misspelled(text):\n",
    "    \"\"\" Check for misspelled words in text \"\"\"\n",
    "    blob = TextBlob(text.lower())\n",
    "    words = blob.words\n",
    "\n",
    "    # Count words that might be misspelled\n",
    "    misspelled_words = []\n",
    "    for w in words:\n",
    "        if len(w) > 2:  # Ignore very short words\n",
    "            corrected_word = TextBlob(w).correct()\n",
    "            if str(corrected_word).lower() != w.lower():\n",
    "                misspelled_words.append(w)\n",
    "\n",
    "    return misspelled_words\n",
    "\n",
    "# Check misspellings in a sample of reviews\n",
    "sample_size = 1000\n",
    "sample_reviews = df['review_text'].sample(n=sample_size, random_state=42)\n",
    "\n",
    "all_errors = []\n",
    "reviews_with_errors = 0\n",
    "\n",
    "print(f\"Checking spelling in {sample_size} reviews...\")\n",
    "\n",
    "for review in sample_reviews:\n",
    "    errors = is_misspelled(review)\n",
    "    if errors:\n",
    "        reviews_with_errors += 1\n",
    "        all_errors.extend(errors)\n",
    "\n",
    "# Summary statistics\n",
    "error_rate = (reviews_with_errors / sample_size) * 100\n",
    "unique_errors = set(all_errors)\n",
    "\n",
    "print(f\"Reviews with potential spelling errors: {reviews_with_errors}/{sample_size} ({error_rate:.1f}%)\")\n",
    "print(f\"Total potential errors found: {len(all_errors)}\")\n",
    "print(f\"Unique misspelled words: {len(unique_errors)}\")\n",
    "\n",
    "# Display most common misspelled words\n",
    "error_counts = Counter(all_errors)\n",
    "print(\"\\nMost Common Potential Misspelled Words:\")\n",
    "for word, count in error_counts.most_common(20):\n",
    "    print(f\"   {word.ljust(15)}: {count} occurrences\")\n",
    "print(\"\\nSpelling check complete!\")"
   ],
   "id": "77d6ed0bd31dc01b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking spelling in 1000 reviews...\n",
      "Reviews with potential spelling errors: 236/1000 (23.6%)\n",
      "Total potential errors found: 236\n",
      "Unique misspelled words: 2\n",
      "\n",
      "Most Common Potential Misspelled Words:\n",
      "   packaging      : 156 occurrences\n",
      "   unhelpful      : 80 occurrences\n",
      "\n",
      "Spelling check complete!\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> **23.6%** error rate sounds high, but \"Errors\" are false positives as they are valid words. Spell correction might introduce noise, and its execution is slow. additionally, it might recognize platform names as misspelled words. Given these factors, we will not include spelling correction in our final preprocessing pipeline.",
   "id": "c435ff44335c7496"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
