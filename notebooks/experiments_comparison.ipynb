{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6cdaf0aea1464e",
   "metadata": {},
   "source": [
    "## Model Comparison & Method Selection\n",
    "\n",
    "## Purpose\n",
    "This notebook documents our experimental process for selecting optimal preprocessing methods and classification. Results from this notebook will inform final implementation decisions in the main analysis notebook.\n",
    "\n",
    "**Note**: This is an experimental notebook. Only winning approaches will be implemented in the production notebook [sentiment_analysis](/notebooks/sentiment_analysis.ipynb).\n",
    "\n",
    "1. Examine Dataset for Normalization Decisions\n",
    "2. spaCy vs NLTK Lemmatization Comparison\n",
    "3. Spelling Correction Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "8166e55a51d1633c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T10:46:06.804471Z",
     "start_time": "2025-12-08T10:46:06.564677Z"
    }
   },
   "source": [
    "from ftplib import all_errors\n",
    "\n",
    "# Exam the dataset for normalization decision\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Load dataset\n",
    "df_check = pd.read_csv('../data/customer_sentiment.csv')\n",
    "\n",
    "# Sample review texts\n",
    "print(\"\\n1. SAMPLE REVIEW TEXTS (first 10):\")\n",
    "for i, review in enumerate(df_check['review_text'].head(10), 1):\n",
    "    print(f\"\\n   {i}. {review[:]}\")\n",
    "\n",
    "# Platform distribution\n",
    "print(\"\\n2. PLATFORM DISTRIBUTION:\")\n",
    "print(df_check['platform'].value_counts())\n",
    "\n",
    "# Get all words from reviews (lowercased)\n",
    "all_words = ' '.join(df_check['review_text'].str.lower()).split()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "print(\"\\n3. TOP 30 MOST COMMON WORDS IN REVIEWS:\")\n",
    "for word, count in word_counts.most_common(50):\n",
    "    print(f\"   {word.ljust(20)} {count}\")\n",
    "\n",
    "# Check for retail/delivery terms\n",
    "retail_terms = ['delivery', 'deliver', 'delivered', 'shipping', 'shipped', 'ship',\n",
    "                'refund', 'return', 'returned', 'money', 'back',\n",
    "                'order', 'ordered', 'ordering', 'package', 'packaging',\n",
    "                'quality', 'product', 'service', 'customer']\n",
    "\n",
    "print(\"\\n4. FREQUENCY OF RETAIL/DELIVERY TERMS:\")\n",
    "for term in retail_terms:\n",
    "    count = sum(1 for review in df_check['review_text'].str.lower() if term in review)\n",
    "    if count > 0:\n",
    "        print(f\"   {term.ljust(15)} appears in {count} reviews ({count / len(df_check) * 100:.1f}%)\")\n",
    "\n",
    "# 6. Check platform mentions in text\n",
    "print(\"\\n5. PLATFORM NAMES MENTIONED IN REVIEWS:\")\n",
    "platforms = df_check['platform'].unique()\n",
    "for platform in platforms[:]:  # Check first 10 platforms\n",
    "    count = sum(1 for review in df_check['review_text'].str.lower() if platform.lower() in review)\n",
    "    if count > 0:\n",
    "        print(f\"   {platform.ljust(20)}: mentioned {count} times\")\n",
    "print(\"not mentioned\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. SAMPLE REVIEW TEXTS (first 10):\n",
      "\n",
      "   1. very disappointed with the quality.\n",
      "\n",
      "   2. fast delivery and great packaging.\n",
      "\n",
      "   3. very disappointed with the quality.\n",
      "\n",
      "   4. product stopped working after few days.\n",
      "\n",
      "   5. neutral about the quality.\n",
      "\n",
      "   6. amazing experience, highly recommend!\n",
      "\n",
      "   7. great value for money.\n",
      "\n",
      "   8. excellent product! exceeded expectations.\n",
      "\n",
      "   9. product is okay, nothing special.\n",
      "\n",
      "   10. great value for money.\n",
      "\n",
      "2. PLATFORM DISTRIBUTION:\n",
      "platform\n",
      "nykaa                   1301\n",
      "snapdeal                1289\n",
      "others                  1286\n",
      "reliance digital        1279\n",
      "zepto                   1278\n",
      "facebook marketplace    1272\n",
      "paytm mall              1271\n",
      "myntra                  1267\n",
      "croma                   1266\n",
      "flipkart                1264\n",
      "boat                    1257\n",
      "lenskart                1241\n",
      "jiomart                 1240\n",
      "meesho                  1240\n",
      "ajio                    1234\n",
      "bigbasket               1230\n",
      "shopclues               1220\n",
      "tata cliq               1201\n",
      "swiggy instamart        1192\n",
      "amazon                  1172\n",
      "Name: count, dtype: int64\n",
      "\n",
      "3. TOP 30 MOST COMMON WORDS IN REVIEWS:\n",
      "   the                  6978\n",
      "   delivery             5023\n",
      "   quality.             4952\n",
      "   and                  3992\n",
      "   packaging.           3992\n",
      "   product              3972\n",
      "   very                 3932\n",
      "   with                 3932\n",
      "   great                3919\n",
      "   was                  3038\n",
      "   amazing              2109\n",
      "   experience,          2109\n",
      "   highly               2109\n",
      "   recommend!           2109\n",
      "   is                   2064\n",
      "   late                 2044\n",
      "   poor                 2044\n",
      "   not                  2026\n",
      "   worth                2026\n",
      "   price.               2026\n",
      "   customer             2007\n",
      "   service              2007\n",
      "   unhelpful.           2007\n",
      "   satisfied            1980\n",
      "   value                1971\n",
      "   for                  1971\n",
      "   money.               1971\n",
      "   excellent            1970\n",
      "   product!             1970\n",
      "   exceeded             1970\n",
      "   expectations.        1970\n",
      "   disappointed         1952\n",
      "   fast                 1948\n",
      "   stopped              1908\n",
      "   working              1908\n",
      "   after                1908\n",
      "   few                  1908\n",
      "   days.                1908\n",
      "   okay,                1033\n",
      "   nothing              1033\n",
      "   special.             1033\n",
      "   fine,                1031\n",
      "   decent.              1031\n",
      "   neutral              1020\n",
      "   about                1020\n",
      "   works                1018\n",
      "   fine                 1018\n",
      "   but                  1018\n",
      "   could                1018\n",
      "   be                   1018\n",
      "\n",
      "4. FREQUENCY OF RETAIL/DELIVERY TERMS:\n",
      "   delivery        appears in 5023 reviews (20.1%)\n",
      "   deliver         appears in 5023 reviews (20.1%)\n",
      "   money           appears in 1971 reviews (7.9%)\n",
      "   packaging       appears in 3992 reviews (16.0%)\n",
      "   quality         appears in 4952 reviews (19.8%)\n",
      "   product         appears in 5942 reviews (23.8%)\n",
      "   service         appears in 2007 reviews (8.0%)\n",
      "   customer        appears in 2007 reviews (8.0%)\n",
      "\n",
      "5. PLATFORM NAMES MENTIONED IN REVIEWS:\n",
      "not mentioned\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Decision Notes:\n",
    "\n",
    "* No platforms mentioned in text - platform normalization unnecessary\n",
    "* Terms are already simple - \"delivery\", \"quality\", \"product\" are base forms\n",
    "* Lemmatization could be considered for words like \"delivered\" -> \"deliver\",\n",
    "* \"ordered\" -> \"order\",\"packaging\" -> \"package\"\n",
    "* Reviews are short - complex normalization adds small value\n",
    "* Decision: (clean + lemmatize + stopwords)*"
   ],
   "id": "6e3748524ae25142"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## spaCy vs NLTK Lemmatization Comparison",
   "id": "1f18240d17d5d00d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T11:15:43.875303Z",
     "start_time": "2025-12-08T11:14:14.084119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Spelling Quality Check\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "\n",
    "print(\"Spelling Quality Analysis\")\n",
    "print(f\"Analyzing sample of {len(df)} reviews...\\n\")\n",
    "\n",
    "# Function to check if word is likely misspelled\n",
    "def check_spelling_errors(text):\n",
    "    \"\"\"Check for potential spelling errors in text.\"\"\"\n",
    "    blob = TextBlob(text.lower())\n",
    "    words = blob.words\n",
    "\n",
    "    # Count words that might be misspelled\n",
    "    # TextBlob suggests corrections for words it thinks are wrong\n",
    "    misspelled = []\n",
    "    for word in words:\n",
    "        if len(word) > 2:  # Skip very short words\n",
    "            corrected = TextBlob(word).correct()\n",
    "            if str(corrected) != word:\n",
    "                misspelled.append((word, str(corrected)))\n",
    "\n",
    "    return misspelled\n",
    "\n",
    "# Analyze a sample of reviews\n",
    "sample_size = 100\n",
    "sample_reviews = df['review_text'].sample(sample_size, random_state=42)\n",
    "\n",
    "all_errors = []\n",
    "reviews_with_errors = 0\n",
    "\n",
    "for review in sample_reviews:\n",
    "    errors = check_spelling_errors(review)\n",
    "    if errors:\n",
    "        reviews_with_errors += 1\n",
    "        all_errors.extend(errors)\n",
    "\n",
    "# Calculate statistics\n",
    "error_rate = (reviews_with_errors / sample_size) * 100\n",
    "\n",
    "print(f\"Reviews with potential spelling errors: {reviews_with_errors}/{sample_size} ({error_rate:.1f}%)\")\n",
    "print(f\"Total potential errors found: {len(all_errors)}\")\n",
    "\n",
    "# Show most common errors\n",
    "if all_errors:\n",
    "    from collections import Counter\n",
    "    common_errors = Counter(all_errors).most_common(10)\n",
    "\n",
    "    print(f\"\\nMost Common Potential Errors:\")\n",
    "    for (wrong, correct), count in common_errors:\n",
    "        print(f\"  '{wrong}' -> '{correct}' ({count} times)\")\n",
    "\n",
    "# Show some example reviews with errors\n",
    "print(f\"\\nExample Reviews with Potential Spelling Issues:\")\n",
    "count = 0\n",
    "for review in sample_reviews:\n",
    "    errors = check_spelling_errors(review)\n",
    "    if errors and count < 3:\n",
    "        print(f\"\\n{count+1}. Original: {review}\")\n",
    "        print(f\"   Errors found: {errors}\")\n",
    "        count += 1\n",
    "\n",
    "print(\"\\nSpelling check complete!\")"
   ],
   "id": "9cd9b52064544827",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model loaded successfully!\n",
      "NLTK resources ready!\n",
      "Dataset loaded: 25,000 reviews\n",
      "\n",
      "Preprocessing Comparison: NLTK vs spaCy (Sample)\n",
      "\n",
      "Sample 1:\n",
      "Original: very disappointed with the quality.\n",
      "NLTK:     disappointed quality\n",
      "spaCy:    disappoint quality\n",
      "\n",
      "Sample 2:\n",
      "Original: fast delivery and great packaging.\n",
      "NLTK:     fast delivery great packaging\n",
      "spaCy:    fast delivery great packaging\n",
      "\n",
      "Sample 3:\n",
      "Original: very disappointed with the quality.\n",
      "NLTK:     disappointed quality\n",
      "spaCy:    disappoint quality\n",
      "\n",
      "Sample 4:\n",
      "Original: product stopped working after few days.\n",
      "NLTK:     product stopped working day\n",
      "spaCy:    product stop work day\n",
      "\n",
      "Sample 5:\n",
      "Original: neutral about the quality.\n",
      "NLTK:     neutral quality\n",
      "spaCy:    neutral quality\n",
      "\n",
      "Execution Time Comparison - Processing 25,000 reviews\n",
      "Testing NLTK...\n",
      "NLTK Lemmatization: 3.76 seconds\n",
      "Testing spaCy...\n",
      "spaCy Lemmatization: 85.54 seconds\n",
      "\n",
      "Speed Comparison:\n",
      "spaCy is 22.72x slower than NLTK\n",
      "Time difference: 81.78 seconds\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ">We observe that while spaCy provides better verb normalization,smaller vocabularies. However, it is more aggressive, and it is 22.72x slower than NLTK. Given our large dataset size **(25,000 reviews)** and the relatively minor differences in lemmatization for our specific use case, we will proceed with NLTK for lemmatization in our final preprocessing pipeline.",
   "id": "1f0ad92b78b554b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T11:51:58.680531Z",
     "start_time": "2025-12-08T11:51:24.659657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/customer_sentiment.csv')\n",
    "\n",
    "# Function to check if word is misspelled\n",
    "def is_misspelled(text):\n",
    "    \"\"\" Check for misspelled words in text \"\"\"\n",
    "    blob = TextBlob(text.lower())\n",
    "    words = blob.words\n",
    "\n",
    "    # Count words that might be misspelled\n",
    "    misspelled_words = []\n",
    "    for w in words:\n",
    "        if len(w) > 2:  # Ignore very short words\n",
    "            corrected_word = TextBlob(w).correct()\n",
    "            if str(corrected_word).lower() != w.lower():\n",
    "                misspelled_words.append(w)\n",
    "\n",
    "    return misspelled_words\n",
    "\n",
    "# Check misspellings in a sample of reviews\n",
    "sample_size = 1000\n",
    "sample_reviews = df['review_text'].sample(n=sample_size, random_state=42)\n",
    "\n",
    "all_errors = []\n",
    "reviews_with_errors = 0\n",
    "\n",
    "print(f\"Checking spelling in {sample_size} reviews...\")\n",
    "\n",
    "for review in sample_reviews:\n",
    "    errors = is_misspelled(review)\n",
    "    if errors:\n",
    "        reviews_with_errors += 1\n",
    "        all_errors.extend(errors)\n",
    "\n",
    "# Summary statistics\n",
    "error_rate = (reviews_with_errors / sample_size) * 100\n",
    "unique_errors = set(all_errors)\n",
    "\n",
    "print(f\"Reviews with potential spelling errors: {reviews_with_errors}/{sample_size} ({error_rate:.1f}%)\")\n",
    "print(f\"Total potential errors found: {len(all_errors)}\")\n",
    "print(f\"Unique misspelled words: {len(unique_errors)}\")\n",
    "\n",
    "# Display most common misspelled words\n",
    "error_counts = Counter(all_errors)\n",
    "print(\"\\nMost Common Potential Misspelled Words:\")\n",
    "for word, count in error_counts.most_common(20):\n",
    "    print(f\"   {word.ljust(15)}: {count} occurrences\")\n",
    "\n",
    "print(\"\\nSpelling check complete!\")"
   ],
   "id": "77d6ed0bd31dc01b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking spelling in 1000 reviews...\n",
      "Reviews with potential spelling errors: 236/1000 (23.6%)\n",
      "Total potential errors found: 236\n",
      "Unique misspelled words: 2\n",
      "\n",
      "Most Common Potential Misspelled Words:\n",
      "   packaging      : 156 occurrences\n",
      "   unhelpful      : 80 occurrences\n",
      "\n",
      "Spelling check complete!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> 23.6% error rate sounds high,but,\"Errors\" are false positives as it is valid word. Spell correction might introduce noise and it's execution is slow. additionally it might recognize platform names as misspelled words. Given these factors, we will not include spelling correction in our final preprocessing pipeline.",
   "id": "c435ff44335c7496"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
